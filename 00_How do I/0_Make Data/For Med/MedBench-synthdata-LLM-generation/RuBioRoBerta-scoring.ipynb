{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8758687,"sourceType":"datasetVersion","datasetId":5262097},{"sourceId":8776385,"sourceType":"datasetVersion","datasetId":5274909}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ноутбук для обучения модели энкодера на первоначальных синтетических данных и замера качества результатов","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/pavel-blinov/RuMedBench.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seqeval\n!pip install datasets\n!pip install transformers -U\n!pip install accelerate -U\n!pip install evaluate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_json('/kaggle/working/RuMedBench/data/RuMedTop3/train_v1.jsonl',\n                     lines=True)\n\ntest = pd.read_json('/kaggle/working/RuMedBench/data/RuMedTop3/test_v1.jsonl',\n                     lines=True)\n\ndev = pd.read_json('/kaggle/working/RuMedBench/data/RuMedTop3/dev_v1.jsonl',\n                     lines=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# подгрузка синтетических данных\n# в случае проверки на первонаяальных данных не выполнялась\ntrain_synth = pd.read_excel('/kaggle/input/gen-5-5-final/train_augmented_3')\ntrain_synth = train_synth[['idx', 'symptoms', 'code']]\ntrain = pd.concat([train, train_synth], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# преобразование в датасет для trainer'a\n\nto_rename = {'symptoms': 'text', 'code': 'label'}\ntrain.drop(columns='idx', inplace=True)\ntest.drop(columns='idx', inplace=True)\ndev.drop(columns='idx', inplace=True)\n\nlabels = train['code'].unique().tolist()\nn_labels = len(labels)\n\nid2label = dict(zip(range(n_labels), labels))\nlabel2id = dict(zip(labels, range(n_labels)))\n\ntrain['code'] = train['code'].replace(label2id)\ntest['code'] = test['code'].replace(label2id)\ndev['code'] = dev['code'].replace(label2id)\n\ndata = DatasetDict({\n    'train': Dataset.from_pandas(train.rename(columns=to_rename)),\n    'dev': Dataset.from_pandas(dev.rename(columns=to_rename)),\n    'test': Dataset.from_pandas(test.rename(columns=to_rename)),\n})\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\nfrom transformers import AutoTokenizer\n\nmodel_checkpoint = \"alexyalunin/RuBioRoBERTa\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint,\n                                          truncation=True, padding=True,\n                                          max_length=512)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], max_length=512)\n\ntokenized_data = data.map(preprocess_function, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=n_labels,\n    id2label=id2label, label2id=label2id\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"True\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# инициализвация обучения\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_model_augmented\",\n    learning_rate=2e-6,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    evaluation_strategy=\"steps\",\n    eval_steps=100,\n    save_strategy=\"steps\",\n    load_best_model_at_end=True,\n    save_total_limit=1\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"dev\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = AutoModelForSequenceClassification.from_pretrained(\n#     '/content/my_model/checkpoint-8252', num_labels=n_labels,\n#     id2label=id2label, label2id=label2id\n# ).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_top_3(text):\n  text = tokenizer(text)\n  batch = {k: torch.tensor(v).reshape(1, -1).to(device) for k, v in text.items()}\n  outputs = model(input_ids=batch['input_ids'][:, :512],\n                  attention_mask=batch['attention_mask'][:, :512])\n\n  return outputs.logits.argsort()[0][-3:].detach().to('cpu').tolist()[::-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas()\ntest['prediction'] = test['symptoms'].progress_apply(predict_top_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_json('test.jsonl', orient='records', lines=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\nimport os\nimport json\nimport argparse\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom seqeval.metrics import f1_score\nfrom seqeval.metrics import accuracy_score as seq_accuracy_score\n\ndef hit_at_3(y_true, y_pred):\n    assert len(y_true) == len(y_pred)\n    hit_count = 0\n    for l, row in zip(y_true, y_pred):\n        hit_count += l in row\n    return hit_count/float(len(y_true))\n\nfname = 'test.jsonl'\n\nmetrics = {}\nlabel_id = 'code'\n\n\nwith open(fname) as f:\n    result = [json.loads(line) for line in list(f)]\n\ngt = [d[label_id] for d in result]\ntop1 = [d['prediction'][0] for d in result]\ntop3 = [set(d['prediction']) for d in result]\nacc = accuracy_score(gt, top1)*100\nhit = hit_at_3(gt, top3)*100\nmetrics['acc'] = acc\nmetrics['hit3'] = hit\n\ntop3_acc, top3_hit = metrics.get('acc', 0), metrics.get('hit3', 0)\n\nresult_line = '| {:.2f} / {:.2f} |'.format(\n    top3_acc, top3_hit,\n)\nprint('| RuMedTop3\\t  |')\nprint(result_line)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}